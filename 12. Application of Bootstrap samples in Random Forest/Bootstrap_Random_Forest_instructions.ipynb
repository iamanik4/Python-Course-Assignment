{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjzGopb_YcKR"
   },
   "source": [
    "# Application of Bootstrap samples in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zZSCtDI6YcKT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2Y1Z1DoYcKZ"
   },
   "source": [
    " <li> Load the boston house dataset </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wBWRNKCDYcKb"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJ_FwP7xYcKg"
   },
   "source": [
    "### Task: 1\n",
    "<font color='red'><b>Step 1 Creating samples: </b></font> Randomly create 30 samples from the whole boston data points.\n",
    "<ol>\n",
    "<li>Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points</li>\n",
    "<li>Ex: For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly consider we have selected [4, 5, 7, 8, 9, 3] now we will replciate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]</li>\n",
    "<li> we create 30 samples like this </li>\n",
    "<li> Note that as a part of the Bagging when you are taking the random samples make sure each of the sample will have                different set of columns</li>\n",
    "<li> Ex: assume we have 10 columns for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample [7, 9, 1, 4, 5, 6, 2] and so on...</li>\n",
    "<li> Make sure each sample will have atleast 3 feautres/columns/attributes</li>\n",
    "</ol>\n",
    "\n",
    "<font color='red'><b>Step 2 Building High Variance Models on each of the sample and finding train MSE value:</b></font> Build a DecisionTreeRegressor on each of the sample.\n",
    "<ol><li>Build a regression trees on each of 30 samples.</li>\n",
    "<li>computed the predicted values of each data point(506 data points) in your corpus.</li>\n",
    "<li> predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n",
    "<li>Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n",
    "</ol>\n",
    "\n",
    "<font color='red'><b>Step 3 Calculating the OOB score :</b></font>\n",
    "<ol>\n",
    "<li>Computed the predicted values of each data point(506 data points) in your corpus.</li>\n",
    "<li>Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n",
    "<li>Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n",
    "</ol>\n",
    "\n",
    "### Task: 2\n",
    "<pre>\n",
    "<font color='red'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "<ol>\n",
    "<li> Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>\n",
    "</pre>\n",
    "### Task: 3\n",
    "<pre>\n",
    "<font color='red'><b>Given a single query point predict the price of house.</b></font>\n",
    "\n",
    "<li>Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] Predict the house price for this point as mentioned in the step 2 of Task 1. </li>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Creating samples: Randomly create 30 samples from the whole boston data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting x values to dataframe\n",
    "data = pd.DataFrame(data=x[:,:], index= range(len(x)), columns=boston.feature_names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_n_sample = {}\n",
    "Y_n_sample = {}\n",
    "data_sample = {}\n",
    "data_index = {}\n",
    "\n",
    "def create_n_samples(data,y,n):\n",
    "    data_size_60 = (int)(0.6*data.shape[0])\n",
    "    data_size_40 = data.shape[0] - data_size_60\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "#         column sampling\n",
    "        random_n_feature = random.randrange(3, data.shape[1])\n",
    "        data_column = data.sample(random_n_feature,axis = 1)\n",
    "        data_sample[i] = data_column\n",
    "        \n",
    "#         row sampling\n",
    "        idx = random.sample(range(data.shape[0]),data_size_60)\n",
    "        idx2 = random.sample(idx,data_size_40)\n",
    "        idx_row = idx + idx2\n",
    "        \n",
    "        data_index[i] = idx_row\n",
    "        \n",
    "        sample_x = data_column.iloc[idx_row].values\n",
    "        sample_y = y[idx_row]\n",
    "        \n",
    "        X_n_sample[i] = sample_x\n",
    "        Y_n_sample[i] = sample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_square_error(y_orig,y_pred):\n",
    "    return (1/506)*np.sum(np.subtract(y_orig,y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 612.22it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_count = 30\n",
    "create_n_samples(data,y,sample_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 Building High Variance Models on each of the sample and finding train MSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [2,2,3,4,5]\n",
    "b = [2,2,3,4,5]\n",
    "np.sum(np.add(b,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_total = np.zeros(506)\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "for i in range(sample_count):\n",
    "    regressor.fit(X_n_sample[i],Y_n_sample[i])\n",
    "    y_pred_sample = regressor.predict(data_sample[i])\n",
    "#     print(y_pred_sample)\n",
    "    y_pred_total = np.add(y_pred_sample,y_pred_total)\n",
    "y_pred = (1/30)*y_pred_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08183127093613031"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_square_error(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 Calculating the OOB score :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOX</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>5.935</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7979</td>\n",
       "      <td>5.570</td>\n",
       "      <td>98.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0123</td>\n",
       "      <td>5.965</td>\n",
       "      <td>89.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0952</td>\n",
       "      <td>5.813</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3996</td>\n",
       "      <td>5.924</td>\n",
       "      <td>94.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6820</td>\n",
       "      <td>5.813</td>\n",
       "      <td>90.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4534</td>\n",
       "      <td>6.047</td>\n",
       "      <td>88.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4547</td>\n",
       "      <td>6.495</td>\n",
       "      <td>94.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2390</td>\n",
       "      <td>6.674</td>\n",
       "      <td>87.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3053</td>\n",
       "      <td>6.484</td>\n",
       "      <td>93.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1705</td>\n",
       "      <td>6.185</td>\n",
       "      <td>96.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9512</td>\n",
       "      <td>6.229</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4242</td>\n",
       "      <td>6.242</td>\n",
       "      <td>64.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3317</td>\n",
       "      <td>6.750</td>\n",
       "      <td>74.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4106</td>\n",
       "      <td>7.061</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0983</td>\n",
       "      <td>5.762</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7240</td>\n",
       "      <td>5.871</td>\n",
       "      <td>41.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9917</td>\n",
       "      <td>6.312</td>\n",
       "      <td>51.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5459</td>\n",
       "      <td>6.114</td>\n",
       "      <td>79.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1523</td>\n",
       "      <td>5.905</td>\n",
       "      <td>53.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8209</td>\n",
       "      <td>5.454</td>\n",
       "      <td>92.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>5.414</td>\n",
       "      <td>98.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8226</td>\n",
       "      <td>5.093</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1099</td>\n",
       "      <td>5.983</td>\n",
       "      <td>83.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>5.707</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>5.926</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>5.670</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>5.390</td>\n",
       "      <td>72.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8927</td>\n",
       "      <td>5.794</td>\n",
       "      <td>70.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4091</td>\n",
       "      <td>6.019</td>\n",
       "      <td>65.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3999</td>\n",
       "      <td>5.569</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NOX  CHAS     DIS     RM    AGE    ZN\n",
       "0    0.538   0.0  4.0900  6.575   65.2  18.0\n",
       "1    0.469   0.0  4.9671  6.421   78.9   0.0\n",
       "2    0.469   0.0  4.9671  7.185   61.1   0.0\n",
       "3    0.458   0.0  6.0622  6.998   45.8   0.0\n",
       "4    0.458   0.0  6.0622  7.147   54.2   0.0\n",
       "5    0.458   0.0  6.0622  6.430   58.7   0.0\n",
       "6    0.524   0.0  5.5605  6.012   66.6  12.5\n",
       "7    0.524   0.0  5.9505  6.172   96.1  12.5\n",
       "8    0.524   0.0  6.0821  5.631  100.0  12.5\n",
       "9    0.524   0.0  6.5921  6.004   85.9  12.5\n",
       "10   0.524   0.0  6.3467  6.377   94.3  12.5\n",
       "11   0.524   0.0  6.2267  6.009   82.9  12.5\n",
       "12   0.524   0.0  5.4509  5.889   39.0  12.5\n",
       "13   0.538   0.0  4.7075  5.949   61.8   0.0\n",
       "14   0.538   0.0  4.4619  6.096   84.5   0.0\n",
       "15   0.538   0.0  4.4986  5.834   56.5   0.0\n",
       "16   0.538   0.0  4.4986  5.935   29.3   0.0\n",
       "17   0.538   0.0  4.2579  5.990   81.7   0.0\n",
       "18   0.538   0.0  3.7965  5.456   36.6   0.0\n",
       "19   0.538   0.0  3.7965  5.727   69.5   0.0\n",
       "20   0.538   0.0  3.7979  5.570   98.1   0.0\n",
       "21   0.538   0.0  4.0123  5.965   89.2   0.0\n",
       "22   0.538   0.0  3.9769  6.142   91.7   0.0\n",
       "23   0.538   0.0  4.0952  5.813  100.0   0.0\n",
       "24   0.538   0.0  4.3996  5.924   94.1   0.0\n",
       "25   0.538   0.0  4.4546  5.599   85.7   0.0\n",
       "26   0.538   0.0  4.6820  5.813   90.3   0.0\n",
       "27   0.538   0.0  4.4534  6.047   88.8   0.0\n",
       "28   0.538   0.0  4.4547  6.495   94.4   0.0\n",
       "29   0.538   0.0  4.2390  6.674   87.3   0.0\n",
       "..     ...   ...     ...    ...    ...   ...\n",
       "476  0.614   0.0  2.3053  6.484   93.6   0.0\n",
       "477  0.614   0.0  2.1007  5.304   97.3   0.0\n",
       "478  0.614   0.0  2.1705  6.185   96.7   0.0\n",
       "479  0.614   0.0  1.9512  6.229   88.0   0.0\n",
       "480  0.532   0.0  3.4242  6.242   64.7   0.0\n",
       "481  0.532   0.0  3.3317  6.750   74.9   0.0\n",
       "482  0.532   0.0  3.4106  7.061   77.0   0.0\n",
       "483  0.532   0.0  4.0983  5.762   40.3   0.0\n",
       "484  0.583   0.0  3.7240  5.871   41.9   0.0\n",
       "485  0.583   0.0  3.9917  6.312   51.9   0.0\n",
       "486  0.583   0.0  3.5459  6.114   79.8   0.0\n",
       "487  0.583   0.0  3.1523  5.905   53.2   0.0\n",
       "488  0.609   0.0  1.8209  5.454   92.7   0.0\n",
       "489  0.609   0.0  1.7554  5.414   98.3   0.0\n",
       "490  0.609   0.0  1.8226  5.093   98.0   0.0\n",
       "491  0.609   0.0  1.8681  5.983   98.8   0.0\n",
       "492  0.609   0.0  2.1099  5.983   83.5   0.0\n",
       "493  0.585   0.0  2.3817  5.707   54.0   0.0\n",
       "494  0.585   0.0  2.3817  5.926   42.6   0.0\n",
       "495  0.585   0.0  2.7986  5.670   28.8   0.0\n",
       "496  0.585   0.0  2.7986  5.390   72.9   0.0\n",
       "497  0.585   0.0  2.8927  5.794   70.6   0.0\n",
       "498  0.585   0.0  2.4091  6.019   65.3   0.0\n",
       "499  0.585   0.0  2.3999  5.569   73.5   0.0\n",
       "500  0.585   0.0  2.4982  6.027   79.7   0.0\n",
       "501  0.573   0.0  2.4786  6.593   69.1   0.0\n",
       "502  0.573   0.0  2.2875  6.120   76.7   0.0\n",
       "503  0.573   0.0  2.1675  6.976   91.0   0.0\n",
       "504  0.573   0.0  2.3889  6.794   89.3   0.0\n",
       "505  0.573   0.0  2.5050  6.030   80.8   0.0\n",
       "\n",
       "[506 rows x 6 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [00:26<00:00, 19.15it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred_total = []\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    y_pred_sample = 0\n",
    "    k = 0\n",
    "    for j in range(sample_count):\n",
    "        if i  not in data_index[j]:\n",
    "            k+=1\n",
    "            regressor.fit(X_n_sample[j],Y_n_sample[j])\n",
    "            y_pred_sample += regressor.predict(data_sample[j].iloc[i].values.reshape(1, -1))\n",
    "#         print(y_pred_sample)\n",
    "    y_pred_total.append((1/k)*y_pred_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3446294225705779"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_total\n",
    "mean_square_error(y,y_pred_total)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_Random_Forest_instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
