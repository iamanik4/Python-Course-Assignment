{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86Tvnj5UblTy"
   },
   "source": [
    "## Task-D: Collinear features and their effect on linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qn_eOn2EblT3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMoYWIayblUB"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('task_d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfStXG4tblUI",
    "outputId": "ddf4eec6-7f53-4d28-914f-23133957d6d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.581066</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.604025</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-0.665927</td>\n",
       "      <td>-0.536277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.894309</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.883052</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-0.917054</td>\n",
       "      <td>-0.522364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.207552</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.082312</td>\n",
       "      <td>-1.150918</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.166507</td>\n",
       "      <td>0.205738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.364174</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.943643</td>\n",
       "      <td>-1.280666</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-1.266540</td>\n",
       "      <td>-0.665720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737687</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.744934</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-0.792746</td>\n",
       "      <td>-0.735054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z       x*x       2*y  2*z+3*x*x         w  \\\n",
       "0 -0.581066  0.841837 -1.012978 -0.604025  0.841837  -0.665927 -0.536277   \n",
       "1 -0.894309 -0.207835 -1.012978 -0.883052 -0.207835  -0.917054 -0.522364   \n",
       "2 -1.207552  0.212034 -1.082312 -1.150918  0.212034  -1.166507  0.205738   \n",
       "3 -1.364174  0.002099 -0.943643 -1.280666  0.002099  -1.266540 -0.665720   \n",
       "4 -0.737687  1.051772 -1.012978 -0.744934  1.051772  -0.792746 -0.735054   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIIuomCkblUP"
   },
   "outputs": [],
   "source": [
    "X = data.drop(['target'], axis=1).values\n",
    "Y = data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4.54202458e-02, -1.46744180e+00,  5.81716801e-01,\n",
       "         -1.24864784e-02, -1.46744180e+00,  5.89939855e-02,\n",
       "          1.38043580e-01],\n",
       "        [-5.81065904e-01,  6.31902691e-01, -9.43643106e-01,\n",
       "         -6.04024675e-01,  6.31902691e-01, -6.57555878e-01,\n",
       "         -1.89048402e+00],\n",
       "        [-1.05093052e+00,  6.31902691e-01, -8.74308565e-01,\n",
       "         -1.01838044e+00,  6.31902691e-01, -1.02210899e+00,\n",
       "         -1.67303624e+00],\n",
       "        [-1.11201292e-01,  1.26170604e+00, -9.43643106e-01,\n",
       "         -1.64556439e-01,  1.26170604e+00, -2.62030398e-01,\n",
       "         -3.63631706e-01],\n",
       "        [ 1.92487869e+00,  2.09934449e-03,  1.27506221e+00,\n",
       "          2.02999446e+00,  2.09934449e-03,  1.98095483e+00,\n",
       "         -9.90981942e-02],\n",
       "        [-1.05093052e+00, -2.07835104e-01, -1.01297765e+00,\n",
       "         -1.01838044e+00, -2.07835104e-01, -1.03885081e+00,\n",
       "         -1.43304574e+00],\n",
       "        [-7.37687441e-01,  2.12033793e-01, -1.15164673e+00,\n",
       "         -7.44933538e-01,  2.12033793e-01, -8.09487887e-01,\n",
       "         -1.03823234e+00],\n",
       "        [-1.67741667e+00, -2.07835104e-01, -1.08231219e+00,\n",
       "         -1.53179095e+00, -2.07835104e-01, -1.50929593e+00,\n",
       "         -4.72829093e-02],\n",
       "        [-1.20755205e+00,  2.12033793e-01, -1.08231219e+00,\n",
       "         -1.15091848e+00,  2.12033793e-01, -1.16650718e+00,\n",
       "          2.05737674e-01],\n",
       "        [ 2.02041783e-01, -8.37638451e-01,  9.28389507e-01,\n",
       "          1.42373757e-01, -8.37638451e-01,  2.40224179e-01,\n",
       "          1.25492750e+00],\n",
       "        [-5.81065904e-01,  1.47164049e+00, -9.43643106e-01,\n",
       "         -6.04024675e-01,  1.47164049e+00, -6.57555878e-01,\n",
       "          3.95229696e-01],\n",
       "        [ 4.54202458e-02,  8.41837140e-01, -1.08231219e+00,\n",
       "         -1.24864784e-02,  8.41837140e-01, -1.41907845e-01,\n",
       "         -2.44856430e-01],\n",
       "        [ 1.29839254e+00, -1.67737625e+00,  1.06705859e+00,\n",
       "          1.30452309e+00, -1.67737625e+00,  1.30291115e+00,\n",
       "          9.30762903e-01],\n",
       "        [-4.24444366e-01,  8.41837140e-01, -9.43643106e-01,\n",
       "         -4.60325538e-01,  8.41837140e-01, -5.28225324e-01,\n",
       "         -4.44492158e-01],\n",
       "        [-1.36417359e+00,  1.05177159e+00, -1.29031581e+00,\n",
       "         -1.28066624e+00,  1.05177159e+00, -1.30839410e+00,\n",
       "         -1.51203058e+00],\n",
       "        [ 1.45501408e+00,  2.12033793e-01,  1.13639313e+00,\n",
       "          1.48170552e+00,  2.12033793e-01,  1.47074789e+00,\n",
       "          1.09369365e+00],\n",
       "        [-7.37687441e-01,  4.21968242e-01, -1.01297765e+00,\n",
       "         -7.44933538e-01,  4.21968242e-01, -7.92746068e-01,\n",
       "          1.13548931e-01],\n",
       "        [-5.81065904e-01,  4.21968242e-01, -8.04974023e-01,\n",
       "         -6.04024675e-01,  4.21968242e-01, -6.40814059e-01,\n",
       "         -9.79958255e-02],\n",
       "        [ 3.58663321e-01, -1.04757290e+00,  4.43047718e-01,\n",
       "          3.00024267e-01, -1.04757290e+00,  3.23514729e-01,\n",
       "         -5.47497799e-01],\n",
       "        [ 3.58663321e-01, -6.27704002e-01,  1.13639313e+00,\n",
       "          3.00024267e-01, -6.27704002e-01,  4.07223826e-01,\n",
       "         -5.05432967e-02],\n",
       "        [-1.36417359e+00,  2.09934449e-03, -9.43643106e-01,\n",
       "         -1.28066624e+00,  2.09934449e-03, -1.26653955e+00,\n",
       "         -6.65719960e-01],\n",
       "        [ 9.85149470e-01, -6.27704002e-01,  1.27506221e+00,\n",
       "          9.58529052e-01, -6.27704002e-01,  1.01662605e+00,\n",
       "          2.24724411e+00],\n",
       "        [-1.05093052e+00, -2.07835104e-01, -1.01297765e+00,\n",
       "         -1.01838044e+00, -2.07835104e-01, -1.03885081e+00,\n",
       "         -1.66480188e+00],\n",
       "        [ 1.76825716e+00, -2.07835104e-01,  1.06705859e+00,\n",
       "          1.84444121e+00, -2.07835104e-01,  1.78884246e+00,\n",
       "          1.14984834e-01],\n",
       "        [-1.36417359e+00,  6.31902691e-01, -1.01297765e+00,\n",
       "         -1.28066624e+00,  6.31902691e-01, -1.27491046e+00,\n",
       "          3.68155902e-01],\n",
       "        [ 2.02041783e-01, -4.17769553e-01,  5.12382260e-01,\n",
       "          1.42373757e-01, -4.17769553e-01,  1.89998721e-01,\n",
       "         -3.47314072e-01],\n",
       "        [-5.81065904e-01,  1.47164049e+00, -8.74308565e-01,\n",
       "         -6.04024675e-01,  1.47164049e+00, -6.49184968e-01,\n",
       "         -1.06009817e+00],\n",
       "        [ 1.29839254e+00,  4.21968242e-01,  1.27506221e+00,\n",
       "          1.30452309e+00,  4.21968242e-01,  1.32802388e+00,\n",
       "          1.24065846e+00],\n",
       "        [-7.37687441e-01, -1.67737625e+00,  3.04378636e-01,\n",
       "         -7.44933538e-01, -1.67737625e+00, -6.33698785e-01,\n",
       "          1.36351540e+00],\n",
       "        [-7.37687441e-01,  8.41837140e-01, -8.74308565e-01,\n",
       "         -7.44933538e-01,  8.41837140e-01, -7.76004249e-01,\n",
       "         -4.94628747e-01],\n",
       "        [-1.05093052e+00,  6.31902691e-01, -6.66304941e-01,\n",
       "         -1.01838044e+00,  6.31902691e-01, -9.96996263e-01,\n",
       "          3.40778294e-01],\n",
       "        [-8.94308978e-01, -2.07835104e-01, -1.01297765e+00,\n",
       "         -8.83052126e-01, -2.07835104e-01, -9.17054076e-01,\n",
       "         -5.22364042e-01],\n",
       "        [ 6.71906395e-01, -2.07835104e-01,  9.28389507e-01,\n",
       "          6.23696110e-01, -2.07835104e-01,  6.73418752e-01,\n",
       "          8.99483447e-02],\n",
       "        [ 2.02041783e-01, -2.07835104e-01,  1.13639313e+00,\n",
       "          1.42373757e-01, -2.07835104e-01,  2.65336908e-01,\n",
       "          1.04153762e+00],\n",
       "        [-8.94308978e-01, -1.46744180e+00,  3.04378636e-01,\n",
       "         -8.83052126e-01, -1.46744180e+00, -7.58006793e-01,\n",
       "          1.01070437e+00],\n",
       "        [-1.11201292e-01,  6.31902691e-01, -8.04974023e-01,\n",
       "         -1.64556439e-01,  6.31902691e-01, -2.45288579e-01,\n",
       "         -1.61253425e+00],\n",
       "        [ 4.54202458e-02, -1.25750735e+00,  7.89720424e-01,\n",
       "         -1.24864784e-02, -1.25750735e+00,  8.41067144e-02,\n",
       "         -3.19664743e-01],\n",
       "        [-5.81065904e-01,  1.26170604e+00, -9.43643106e-01,\n",
       "         -6.04024675e-01,  1.26170604e+00, -6.57555878e-01,\n",
       "         -1.18216914e+00],\n",
       "        [ 5.15284858e-01, -8.37638451e-01,  7.20385883e-01,\n",
       "          4.60465051e-01, -8.37638451e-01,  5.01396559e-01,\n",
       "          1.28012377e+00],\n",
       "        [ 6.71906395e-01,  2.12033793e-01,  1.34439675e+00,\n",
       "          6.23696110e-01,  2.12033793e-01,  7.23644209e-01,\n",
       "          5.13102602e-01],\n",
       "        [ 5.15284858e-01, -1.04757290e+00,  7.89720424e-01,\n",
       "          4.60465051e-01, -1.04757290e+00,  5.09767469e-01,\n",
       "          2.02307093e-01],\n",
       "        [-5.81065904e-01,  1.47164049e+00, -6.66304941e-01,\n",
       "         -6.04024675e-01,  1.47164049e+00, -6.24072239e-01,\n",
       "         -1.39303650e+00],\n",
       "        [ 8.28527933e-01,  6.31902691e-01,  1.13639313e+00,\n",
       "          7.89717444e-01,  6.31902691e-01,  8.47952217e-01,\n",
       "          1.02133893e+00],\n",
       "        [ 3.58663321e-01,  2.73124718e+00, -9.43643106e-01,\n",
       "          3.00024267e-01,  2.73124718e+00,  1.56096537e-01,\n",
       "         -1.44650062e-01],\n",
       "        [ 8.28527933e-01, -8.37638451e-01,  1.55240038e+00,\n",
       "          7.89717444e-01, -8.37638451e-01,  8.98177675e-01,\n",
       "          1.94454083e+00],\n",
       "        [ 1.61163562e+00, -6.27704002e-01,  1.20572767e+00,\n",
       "          1.66167823e+00, -6.27704002e-01,  1.64109590e+00,\n",
       "         -7.00311876e-01],\n",
       "        [ 2.08150023e+00, -6.27704002e-01,  1.34439675e+00,\n",
       "          2.21833799e+00, -6.27704002e-01,  2.15883666e+00,\n",
       "          1.94105101e+00],\n",
       "        [ 5.15284858e-01,  1.89150938e+00, -1.15164673e+00,\n",
       "          4.60465051e-01,  1.89150938e+00,  2.75381999e-01,\n",
       "         -8.36756163e-01],\n",
       "        [ 2.23812177e+00,  2.09934449e-03,  1.41373130e+00,\n",
       "          2.40947180e+00,  2.09934449e-03,  2.33922977e+00,\n",
       "          1.67479348e+00],\n",
       "        [-7.37687441e-01,  8.41837140e-01, -1.08231219e+00,\n",
       "         -7.44933538e-01,  8.41837140e-01, -8.01116978e-01,\n",
       "         -1.20189106e+00],\n",
       "        [-5.81065904e-01,  8.41837140e-01, -1.01297765e+00,\n",
       "         -6.04024675e-01,  8.41837140e-01, -6.65926787e-01,\n",
       "         -4.06519765e-01],\n",
       "        [-8.94308978e-01,  1.05177159e+00, -1.01297765e+00,\n",
       "         -8.83052126e-01,  1.05177159e+00, -9.17054076e-01,\n",
       "         -1.08705470e+00],\n",
       "        [-1.67741667e+00, -4.17769553e-01, -1.01297765e+00,\n",
       "         -1.53179095e+00, -4.17769553e-01, -1.50092502e+00,\n",
       "          1.63838184e-01],\n",
       "        [-4.24444366e-01, -8.37638451e-01,  7.20385883e-01,\n",
       "         -4.60325538e-01, -8.37638451e-01, -3.27323493e-01,\n",
       "         -6.55300133e-01],\n",
       "        [ 4.54202458e-02, -1.46744180e+00,  6.51051342e-01,\n",
       "         -1.24864784e-02, -1.46744180e+00,  6.73648952e-02,\n",
       "         -3.30207602e-01],\n",
       "        [-4.24444366e-01,  6.31902691e-01, -1.01297765e+00,\n",
       "         -4.60325538e-01,  6.31902691e-01, -5.36596234e-01,\n",
       "         -1.10420653e+00],\n",
       "        [-5.81065904e-01,  8.41837140e-01, -1.01297765e+00,\n",
       "         -6.04024675e-01,  8.41837140e-01, -6.65926787e-01,\n",
       "         -5.36277029e-01],\n",
       "        [ 1.92487869e+00, -2.07835104e-01,  1.48306584e+00,\n",
       "          2.02999446e+00, -2.07835104e-01,  2.00606756e+00,\n",
       "          1.36780975e+00],\n",
       "        [ 8.28527933e-01, -4.17769553e-01,  1.13639313e+00,\n",
       "          7.89717444e-01, -4.17769553e-01,  8.47952217e-01,\n",
       "          8.74213733e-01],\n",
       "        [-8.94308978e-01,  2.09934449e-03, -9.43643106e-01,\n",
       "         -8.83052126e-01,  2.09934449e-03, -9.08683166e-01,\n",
       "         -1.14312018e-01],\n",
       "        [ 1.45501408e+00, -4.17769553e-01,  9.97724048e-01,\n",
       "          1.48170552e+00, -4.17769553e-01,  1.45400607e+00,\n",
       "          9.49332468e-02],\n",
       "        [ 3.58663321e-01, -2.07835104e-01,  9.28389507e-01,\n",
       "          3.00024267e-01, -2.07835104e-01,  3.82111097e-01,\n",
       "          1.71647571e+00],\n",
       "        [ 1.14177101e+00, -4.17769553e-01,  9.97724048e-01,\n",
       "          1.13013093e+00, -4.17769553e-01,  1.13758569e+00,\n",
       "          1.98596718e-02],\n",
       "        [-4.24444366e-01,  2.10144383e+00, -9.43643106e-01,\n",
       "         -4.60325538e-01,  2.10144383e+00, -5.28225324e-01,\n",
       "          2.78895657e-01],\n",
       "        [ 3.58663321e-01,  1.47164049e+00, -8.04974023e-01,\n",
       "          3.00024267e-01,  1.47164049e+00,  1.72838356e-01,\n",
       "          2.70811007e-03],\n",
       "        [ 1.76825716e+00, -4.17769553e-01,  1.20572767e+00,\n",
       "          1.84444121e+00, -4.17769553e-01,  1.80558428e+00,\n",
       "          1.08190246e+00],\n",
       "        [-1.05093052e+00,  2.09934449e-03, -8.74308565e-01,\n",
       "         -1.01838044e+00,  2.09934449e-03, -1.02210899e+00,\n",
       "         -9.83345788e-01],\n",
       "        [-1.11201292e-01,  1.68157493e+00, -1.08231219e+00,\n",
       "         -1.64556439e-01,  1.68157493e+00, -2.78772218e-01,\n",
       "         -2.59712709e-01],\n",
       "        [ 3.58663321e-01, -6.27704002e-01,  8.59054966e-01,\n",
       "          3.00024267e-01, -6.27704002e-01,  3.73740187e-01,\n",
       "         -4.53637247e-02],\n",
       "        [-7.37687441e-01,  1.05177159e+00, -1.01297765e+00,\n",
       "         -7.44933538e-01,  1.05177159e+00, -7.92746068e-01,\n",
       "         -7.35054120e-01],\n",
       "        [-1.11201292e-01,  6.31902691e-01, -9.43643106e-01,\n",
       "         -1.64556439e-01,  6.31902691e-01, -2.62030398e-01,\n",
       "          5.03334896e-01],\n",
       "        [ 1.14177101e+00, -1.88731069e+00,  1.13639313e+00,\n",
       "          1.13013093e+00, -1.88731069e+00,  1.15432751e+00,\n",
       "          5.61001444e-01],\n",
       "        [ 1.92487869e+00,  2.09934449e-03,  1.06705859e+00,\n",
       "          2.02999446e+00,  2.09934449e-03,  1.95584211e+00,\n",
       "          1.04135740e+00],\n",
       "        [ 2.02041783e-01, -1.25750735e+00,  7.20385883e-01,\n",
       "          1.42373757e-01, -1.25750735e+00,  2.15111450e-01,\n",
       "         -1.56537249e-01],\n",
       "        [-1.52079513e+00, -1.67737625e+00, -1.08231219e+00,\n",
       "         -1.40762373e+00, -1.67737625e+00, -1.39754429e+00,\n",
       "          4.39926934e-01]]),\n",
       " array([1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "        1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ydm98u3EblUU"
   },
   "source": [
    "### Doing perturbation test to check the presence of collinearity  \n",
    "\n",
    "#### Task: 1 Logistic Regression\n",
    "<pre>\n",
    "\n",
    "\n",
    "1. <b>Finding the Correlation between the features</b>\n",
    "    a. check the correlation between the features\n",
    "    b. plot heat map of correlation matrix using seaborn heatmap\n",
    "2. <b>Finding the best model for the given data</b>\n",
    "    a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "    b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or         random search CV make sure you choose the alpha in log space)\n",
    "    c. Creat a new Logistic regression with the best alpha(search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "    \n",
    "3. <b>Getting the weights with the original data</b>\n",
    "    a. train the 'best_model' with X, Y\n",
    "    b. Check the accuracy of the model 'best_model_accuracy'\n",
    "    c. Get the weights W using best_model.coef_\n",
    "\n",
    "4. <b>Modifying original data</b>\n",
    "    a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)\n",
    "    b. Train the same 'best_model' with data (X', Y)\n",
    "    c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "    d. Get the weights W' using best_model.coef_\n",
    "    \n",
    "5. <b> Checking deviations in metric and weights </b>\n",
    "    a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "    b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "    c. print the top 4 features which have higher % change in weights compare to the other feature\n",
    "\n",
    "</pre>\n",
    "\n",
    "#### Task: 2 Linear SVM\n",
    "\n",
    "<pre>\n",
    "1. Do the same steps (2, 3, 4, 5) we have done in the above task 1.\n",
    "</pre>\n",
    "\n",
    "<strong><font color='red'>Do write the observations based on the results you get from the deviations of weights in both Logistic Regression and linear SVM</font></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lai8wXU1pmSb"
   },
   "source": [
    "# Task: 1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Finding the Correlation between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.205926</td>\n",
       "      <td>0.812458</td>\n",
       "      <td>0.997947</td>\n",
       "      <td>-0.205926</td>\n",
       "      <td>0.996252</td>\n",
       "      <td>0.583277</td>\n",
       "      <td>0.728290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>-0.205926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>-0.690684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.812458</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807137</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>0.847163</td>\n",
       "      <td>0.674486</td>\n",
       "      <td>0.969990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x*x</th>\n",
       "      <td>0.997947</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>0.807137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>0.583803</td>\n",
       "      <td>0.719570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2*y</th>\n",
       "      <td>-0.205926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>-0.690684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <td>0.996252</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>0.847163</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606860</td>\n",
       "      <td>0.764729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0.583277</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>0.674486</td>\n",
       "      <td>0.583803</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>0.606860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.728290</td>\n",
       "      <td>-0.690684</td>\n",
       "      <td>0.969990</td>\n",
       "      <td>0.719570</td>\n",
       "      <td>-0.690684</td>\n",
       "      <td>0.764729</td>\n",
       "      <td>0.641750</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x         y         z       x*x       2*y  2*z+3*x*x  \\\n",
       "x          1.000000 -0.205926  0.812458  0.997947 -0.205926   0.996252   \n",
       "y         -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123   \n",
       "z          0.812458 -0.602663  1.000000  0.807137 -0.602663   0.847163   \n",
       "x*x        0.997947 -0.209289  0.807137  1.000000 -0.209289   0.997457   \n",
       "2*y       -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123   \n",
       "2*z+3*x*x  0.996252 -0.261123  0.847163  0.997457 -0.261123   1.000000   \n",
       "w          0.583277 -0.401790  0.674486  0.583803 -0.401790   0.606860   \n",
       "target     0.728290 -0.690684  0.969990  0.719570 -0.690684   0.764729   \n",
       "\n",
       "                  w    target  \n",
       "x          0.583277  0.728290  \n",
       "y         -0.401790 -0.690684  \n",
       "z          0.674486  0.969990  \n",
       "x*x        0.583803  0.719570  \n",
       "2*y       -0.401790 -0.690684  \n",
       "2*z+3*x*x  0.606860  0.764729  \n",
       "w          1.000000  0.641750  \n",
       "target     0.641750  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. check the correlation between the features\n",
    "\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xc22da20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# b. plot heat map of correlation matrix using seaborn heatmap\n",
    "\n",
    "sns.heatmap(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding the best model for the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "\n",
    "cfg = SGDClassifier(loss='log')\n",
    "cfg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=1, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation \n",
    "\n",
    "tuned_para = [{'alpha':[10**-4,10**-2,10**0,10**2,10**4]}]\n",
    "model = GridSearchCV(SGDClassifier(loss='log',random_state = 1),tuned_para)\n",
    "model.fit(X_train,Y_train)\n",
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Creat a new Logistic regression with the best alpha(search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "\n",
    "best_model = SGDClassifier(loss='log',alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Getting the weights with the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. train the 'best_model' with X, Y\n",
    "\n",
    "best_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# b. Check the accuracy of the model 'best_model_accuracy'\n",
    "\n",
    "best_model_accuracy = best_model.score(X_test,Y_test)\n",
    "print(best_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71392077 -0.84989874  1.83835164  0.63333854 -0.84989874  0.79195873\n",
      "   0.47601577]]\n"
     ]
    }
   ],
   "source": [
    "# c. Get the weights W using best_model.coef_\n",
    "W = best_model.coef_\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modifying original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)\n",
    "\n",
    "X_train_new = X_train+0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b. Train the same 'best_model' with data (X', Y)\n",
    "best_model.fit(X_train_new,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "best_model_accuracy_edited = best_model.score(X_test,Y_test)\n",
    "print(best_model_accuracy_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.75015978 -0.88687805  1.70383348  0.69805751 -0.88687805  0.83399534\n",
      "   0.47021967]]\n"
     ]
    }
   ],
   "source": [
    "# d. Get the weights W' using best_model.coef_\n",
    "W_error = best_model.coef_\n",
    "print(W_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Checking deviations in metric and weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "print(best_model_accuracy - best_model_accuracy_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03623901 0.03697931 0.13451815 0.06471897 0.03697931 0.0420366\n",
      "  0.0057961 ]]\n"
     ]
    }
   ],
   "source": [
    "# b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "W_change = abs(W-W_error)\n",
    "print(W_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 features which have higher % change in weights compare to the other feature\n",
      "('x*x', 10.21870045461081)\n",
      "('z', 7.317324378945202)\n",
      "('2*z+3*x*x', 5.307928468448101)\n",
      "('x', 5.076054953800743)\n"
     ]
    }
   ],
   "source": [
    "# c. print the top 4 features which have higher % change in weights compare to the other feature\n",
    "feat = list(data.columns) \n",
    "percent_values = list((W_change*100/abs(W))[0])\n",
    "values = sorted(zip(feat,percent_values),key = lambda x: x[1],reverse = True)\n",
    "# print(values)\n",
    "i = 0\n",
    "print('Top 4 features which have higher % change in weights compare to the other feature')\n",
    "for x,y in enumerate(values):\n",
    "    if i<4:\n",
    "        print(y)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lai8wXU1pmSb"
   },
   "source": [
    "## Task: 2 Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding the best model for the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "\n",
    "cfg = SGDClassifier(loss='hinge')\n",
    "cfg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=1, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation \n",
    "\n",
    "tuned_para = [{'alpha':[10**-4,10**-2,10**0,10**2,10**4]}]\n",
    "model = GridSearchCV(SGDClassifier(loss='hinge',random_state = 1),tuned_para)\n",
    "model.fit(X_train,Y_train)\n",
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Creat a new Logistic regression with the best alpha(search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "\n",
    "best_model = SGDClassifier(loss='hinge',alpha=0.01,random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Getting the weights with the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=1, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. train the 'best_model' with X, Y\n",
    "\n",
    "best_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# b. Check the accuracy of the model 'best_model_accuracy'\n",
    "\n",
    "best_model_accuracy = best_model.score(X_test,Y_test)\n",
    "print(best_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.45215365 -0.51807836  1.48045548  0.42888775 -0.51807836  0.56474155\n",
      "   0.32196128]]\n"
     ]
    }
   ],
   "source": [
    "# c. Get the weights W using best_model.coef_\n",
    "W = best_model.coef_\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modifying original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)\n",
    "\n",
    "X_train_new = X_train+0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=1, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b. Train the same 'best_model' with data (X', Y)\n",
    "best_model.fit(X_train_new,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "best_model_accuracy_edited = best_model.score(X_test,Y_test)\n",
    "print(best_model_accuracy_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73126318 -0.78528992  1.97252728  0.69455317 -0.78528992  0.86340519\n",
      "   0.24176932]]\n"
     ]
    }
   ],
   "source": [
    "# d. Get the weights W' using best_model.coef_\n",
    "W_error = best_model.coef_\n",
    "print(W_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Checking deviations in metric and weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "print(best_model_accuracy - best_model_accuracy_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27910953 0.26721156 0.4920718  0.26566542 0.26721156 0.29866364\n",
      "  0.08019196]]\n"
     ]
    }
   ],
   "source": [
    "# b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "W_change = abs(W-W_error)\n",
    "print(W_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('x*x', 61.94287977806593), ('x', 61.72891086334997), ('2*z+3*x*x', 52.885012958777835), ('y', 51.57744005458996), ('2*y', 51.57744005458996), ('z', 33.23786540840495), ('w', 24.90733150080833)]\n",
      "Top 4 features which have higher % change in weights compare to the other feature\n",
      "('x*x', 61.94287977806593)\n",
      "('x', 61.72891086334997)\n",
      "('2*z+3*x*x', 52.885012958777835)\n",
      "('y', 51.57744005458996)\n"
     ]
    }
   ],
   "source": [
    "# c. print the top 4 features which have higher % change in weights compare to the other feature\n",
    "feat = list(data.columns) \n",
    "percent_values = list((W_change*100/abs(W))[0])\n",
    "values = sorted(zip(feat,percent_values),key = lambda x: x[1],reverse = True)\n",
    "print(values)\n",
    "i = 0\n",
    "print('Top 4 features which have higher % change in weights compare to the other feature')\n",
    "for x,y in enumerate(values):\n",
    "    if i<4:\n",
    "        print(y)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "8D_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
